ğŸš¢ Titanic Survival Prediction â€“ Data Analysis & Machine Learning
ğŸ“Œ Project Overview

This project focuses on exploratory data analysis (EDA), feature engineering, and machine learning modeling to predict the survival of passengers aboard the Titanic.
The goal is not just prediction accuracy, but understanding the factors that influenced survival using data-driven insights.

ğŸ¯ Objectives

Analyze passenger data to uncover survival patterns

Perform structured exploratory data analysis (EDA)

Engineer meaningful features from raw data

Build and evaluate a machine learning model to predict survival

ğŸ§° Tools & Technologies Used

Python

NumPy â€“ numerical operations

Pandas â€“ data manipulation

Matplotlib & Seaborn â€“ data visualization

Scikit-learn â€“ machine learning models & evaluation

ğŸ“‚ Project Structure
Titanic-Dataset-Analysis/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ train.csv
â”‚   â””â”€â”€ processed_titanic.csv
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_eda.ipynb
â”‚   â”œâ”€â”€ 02_feature_engineering.ipynb
â”‚   â””â”€â”€ 03_modeling.ipynb
â”‚
â”œâ”€â”€ README.md

ğŸ“˜ Notebook Breakdown
1ï¸âƒ£ Exploratory Data Analysis (01_eda.ipynb)

Dataset overview and missing value analysis

Survival rate distribution

Univariate, bivariate, and multivariate analysis

Visual insights on survival vs gender, class, age, and fare

Key Insights:

Female passengers had a significantly higher survival rate

First-class passengers survived more than lower classes

Younger passengers had better survival chances

2ï¸âƒ£ Feature Engineering (02_feature_engineering.ipynb)

Handling missing values using group-based statistics

Creating new features:

FamilySize

IsAlone

Passenger Title extracted from names

Encoding categorical variables

Dropping irrelevant features

Saving a clean, model-ready dataset

3ï¸âƒ£ Modeling & Evaluation (03_modeling.ipynb)

Trainâ€“test data split

Logistic Regression model training

Model evaluation using:

Accuracy

Confusion Matrix

Precision, Recall, and F1-score

Interpretation of important features

ğŸ“Š Model Performance

The model demonstrates reasonable performance given the dataset size and class imbalance.
Evaluation metrics beyond accuracy were used to ensure balanced assessment.

ğŸ” Key Learnings

Importance of EDA before modeling

Feature engineering can significantly improve model interpretability

Accuracy alone is not sufficient for imbalanced datasets

Structured ML pipelines improve reproducibility and clarity

ğŸš€ Future Improvements

Compare multiple models (Random Forest, XGBoost)

Apply cross-validation

Hyperparameter tuning

Deploy as a web app using Streamlit

Add ROC-AUC and Precisionâ€“Recall analysis

ğŸ§  Interview-Ready Summary

â€œThis project demonstrates a complete data science workflow â€” from exploratory data analysis and feature engineering to machine learning modeling and evaluation â€” with a strong emphasis on interpretability and structured analysis.â€